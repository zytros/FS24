{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.integrate import cumtrapz\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import numpy as np \n",
    "import heapq\n",
    "from joblib import load \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_train_data = []\n",
    "for i in range(0, 50):\n",
    "    all_train_data.append(Recording(f'data/train/train_trace_{i:03d}.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.079890</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.159780</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.239670</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.319560</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.399450</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.559229</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.639119</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.719009</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.798899</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.878789</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.958679</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.038569</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.118459</td>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1.198349</td>\n",
       "      <td>413.787807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1.278238</td>\n",
       "      <td>413.787807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.358128</td>\n",
       "      <td>415.056728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1.438018</td>\n",
       "      <td>415.056728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1.517908</td>\n",
       "      <td>415.056728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      time       value\n",
       "0    0  0.000000  407.332413\n",
       "1    0  0.079890  407.332413\n",
       "2    0  0.159780  407.332413\n",
       "3    0  0.239670  407.332413\n",
       "4    0  0.319560  407.332413\n",
       "5    0  0.399450  407.332413\n",
       "6    0  0.479339  407.332413\n",
       "7    0  0.559229  407.332413\n",
       "8    0  0.639119  407.332413\n",
       "9    0  0.719009  407.332413\n",
       "10   0  0.798899  407.332413\n",
       "11   0  0.878789  407.332413\n",
       "12   0  0.958679  407.332413\n",
       "13   0  1.038569  407.332413\n",
       "14   0  1.118459  407.332413\n",
       "15   0  1.198349  413.787807\n",
       "16   0  1.278238  413.787807\n",
       "17   0  1.358128  415.056728\n",
       "18   0  1.438018  415.056728\n",
       "19   0  1.517908  415.056728"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_list = []  # To store all the data points\n",
    "\n",
    "'''# Process each recording\n",
    "for i, recording in enumerate(all_train_data):\n",
    "    # Ensure that each sensor has timestamps\n",
    "    timestamps_ax = recording.data['ax'].timestamps\n",
    "    timestamps_ay = recording.data['ay'].timestamps\n",
    "    timestamps_az = recording.data['az'].timestamps\n",
    "    timestamps_altitude = recording.data['altitude'].timestamps\n",
    "    \n",
    "    # Collect data for ax, ay, az, and altitude with actual timestamps\n",
    "    data_list.extend([\n",
    "        {\"id\": f\"{i}_ax\", \"time\": ts, \"sensor\": \"ax\", \"value\": val}\n",
    "        for ts, val in zip(timestamps_ax, recording.data['ax'].values)\n",
    "    ])\n",
    "    data_list.extend([\n",
    "        {\"id\": f\"{i}_ay\", \"time\": ts, \"sensor\": \"ay\", \"value\": val}\n",
    "        for ts, val in zip(timestamps_ay, recording.data['ay'].values)\n",
    "    ])\n",
    "    data_list.extend([\n",
    "        {\"id\": f\"{i}_az\", \"time\": ts, \"sensor\": \"az\", \"value\": val}\n",
    "        for ts, val in zip(timestamps_az, recording.data['az'].values)\n",
    "    ])\n",
    "    data_list.extend([\n",
    "        {\"id\": f\"{i}_altitude\", \"time\": ts, \"sensor\": \"altitude\", \"value\": val}\n",
    "        for ts, val in zip(timestamps_altitude, recording.data['altitude'].values)\n",
    "    ])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_list)'''\n",
    "\n",
    "\n",
    "# Process each recording\n",
    "for i, recording in enumerate(all_train_data):\n",
    "\n",
    "    timestamps_altitude = recording.data['altitude'].timestamps\n",
    "    \n",
    "    data_list.extend([\n",
    "        {\"id\": i, \"time\": ts, \"value\": val}\n",
    "        for ts, val in zip(timestamps_altitude, recording.data['altitude'].values)\n",
    "    ])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head(20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>F_x</th>\n",
       "      <th>F_y</th>\n",
       "      <th>F_z</th>\n",
       "      <th>T_x</th>\n",
       "      <th>T_y</th>\n",
       "      <th>T_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>61</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>61</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  time  F_x  F_y  F_z  T_x  T_y  T_z\n",
       "0   1     0   -1   -1   63   -3   -1    0\n",
       "1   1     1    0    0   62   -3   -1    0\n",
       "2   1     2   -1   -1   61   -3    0    0\n",
       "3   1     3   -1   -1   63   -2   -1    0\n",
       "4   1     4   -1   -1   63   -3   -1    0\n",
       "5   1     5   -1   -1   63   -3   -1    0\n",
       "6   1     6   -1   -1   63   -3    0    0\n",
       "7   1     7   -1   -1   63   -3   -1    0\n",
       "8   1     8   -1   -1   63   -3   -1    0\n",
       "9   1     9   -1   -1   61   -3    0    0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tsfresh\n",
    "from tsfresh.examples import load_robot_execution_failures\n",
    "tsfresh.examples.robot_execution_failures.download_robot_execution_failures()\n",
    "df_ex, _ = load_robot_execution_failures()\n",
    "df_ex.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique IDs found: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
      " '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49']\n"
     ]
    }
   ],
   "source": [
    "# Print all unique IDs to check if they are being generated correctly\n",
    "unique_ids = df['id'].unique()\n",
    "print(\"Unique IDs found:\", unique_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Extract features\n",
    "extracted_features = extract_features(df, column_id='id', column_sort='time', impute_function=impute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "df must be a DataFrame or a dict of DataFrames. See https://tsfresh.readthedocs.io/en/latest/text/data_formats.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfresh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m select_features\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfresh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_relevant_features\n\u001b[0;32m----> 7\u001b[0m X1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_sort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m X2 \u001b[38;5;241m=\u001b[39m extract_features(ax, column_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m      9\u001b[0m X3 \u001b[38;5;241m=\u001b[39m extract_features(ay, column_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mhealth24/lib/python3.10/site-packages/tsfresh/feature_extraction/extraction.py:164\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor, pivot)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_do_extraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeseries_container\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_kind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_kind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_sort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_sort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_warnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_fc_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_fc_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind_to_fc_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind_to_fc_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistributor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpivot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Impute the result if requested\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impute_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mhealth24/lib/python3.10/site-packages/tsfresh/feature_extraction/extraction.py:260\u001b[0m, in \u001b[0;36m_do_extraction\u001b[0;34m(df, column_id, column_value, column_kind, column_sort, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, show_warnings, distributor, pivot)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_extraction\u001b[39m(\n\u001b[1;32m    194\u001b[0m     df,\n\u001b[1;32m    195\u001b[0m     column_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     pivot,\n\u001b[1;32m    207\u001b[0m ):\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    Wrapper around the _do_extraction_on_chunk, which calls it on all chunks in the data frame.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    A chunk is a subset of the data, with a given kind and id - so a single time series.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    :rtype: pd.DataFrame\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mto_tsdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_kind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_sort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m distributor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Iterable):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mhealth24/lib/python3.10/site-packages/tsfresh/feature_extraction/data.py:487\u001b[0m, in \u001b[0;36mto_tsdata\u001b[0;34m(df, column_id, column_kind, column_value, column_sort)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DaskTsAdapter(df, column_id, column_kind, column_value, column_sort)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf must be a DataFrame or a dict of DataFrames. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://tsfresh.readthedocs.io/en/latest/text/data_formats.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: df must be a DataFrame or a dict of DataFrames. See https://tsfresh.readthedocs.io/en/latest/text/data_formats.html"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.selection import select_features\n",
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = extracted_features\n",
    "\n",
    "\n",
    "y = []\n",
    "for recording in all_train_data:\n",
    "    y.append(recording.labels['path_idx'])\n",
    "y = np.array(y) \n",
    "\n",
    "X_filtered = select_features(X, y)\n",
    "\n",
    "features_filtered_direct = extract_relevant_features(X_filtered, y, column_id='id', column_sort='time')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10],\n",
    "    'max_depth': [ 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross validation and print training and test scores\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=2, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Print the mean training and testing scores for each parameter set\n",
    "for i in range(len(results['params'])):\n",
    "    print(f\"Parameters: {results['params'][i]}\")\n",
    "    print(f\"Mean Training Score: {results['mean_train_score'][i]:.3f}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][i]:.3f}\")\n",
    "    print('-' * 40)\n",
    "\n",
    "# If you want to print scores for each individual fold as well\n",
    "for i in range(len(results['params'])):\n",
    "    for j in range(2):\n",
    "        print(f\"Parameters: {results['params'][i]} - Fold {j+1}\")\n",
    "        print(f\"Training Score: {results[f'split{j}_train_score'][i]:.3f}\")\n",
    "        print(f\"Test Score: {results[f'split{j}_test_score'][i]:.3f}\")\n",
    "    print('-' * 40)\n",
    "\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train the classifier with the best parameters\n",
    "clf = RandomForestClassifier(**grid_search.best_params_, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_accuracy = sklearn.metrics.balanced_accuracy_score(y_test, y_pred, adjusted=True)\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy}\")\n",
    "\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "\n",
    "# plot y_test2 and y_pred2\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_test, label='y_test2')\n",
    "plt.plot(y_pred, label='y_pred2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhealth24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
