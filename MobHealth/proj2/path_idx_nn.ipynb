{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the template for the submission. You can develop your algorithm in a regular Python script and copy the code here for submission.\n",
    "\n",
    "# TEAM NAME ON KAGGLE\n",
    "# \"EXAMPLE_GROUP\"\n",
    "\n",
    "# GROUP NUMBER\n",
    "# \"group_XX\"\n",
    "\n",
    "# TEAM MEMBERS (E-MAIL, LEGI, KAGGLE USERNAME):\n",
    "# \"examplestudent1@ethz.ch\", \"12-345-678\", \"eXampl3stdNtone\" \n",
    "# \"examplestudent2@ethz.ch\", \"12-345-679\", \"xXexamplestudent2Xx\"\n",
    "# \"examplestudent3@ethz.ch\", \"12-345-670\", \"mhealth_student_98\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For interactive graphs\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the path for all test traces\n",
    "'''\n",
    "dir_traces_test = 'data/test'\n",
    "filenames_test = [join(dir_traces_test, f) for f in listdir(dir_traces_test) if isfile(join(dir_traces_test, f))]\n",
    "filenames_test.sort()\n",
    "recordings_test = []\n",
    "for fn in filenames_test:\n",
    "    rec = Recording(fn)\n",
    "    match = re.search(r'(\\d{3})\\.pkl$', fn)\n",
    "    if match:\n",
    "        id = int(match.group(1))\n",
    "        rec.id = id\n",
    "    else:\n",
    "        raise ValueError(f'Filename {fn} does not match expected format')\n",
    "    recordings_test.append(rec)\n",
    "'''\n",
    "    \n",
    "    \n",
    "dir_traces_train = 'data/train'\n",
    "filenames_train = [join(dir_traces_train, f) for f in listdir(dir_traces_train) if isfile(join(dir_traces_train, f))]\n",
    "filenames_train.sort()\n",
    "\n",
    "alts = []\n",
    "path_idxs = []\n",
    "activities = []\n",
    "for fn in filenames_train:\n",
    "    rec = Recording(fn)\n",
    "    alts.append(rec.data['altitude'].values)\n",
    "    path_idxs.append(rec.labels['path_idx'])\n",
    "    activities.append(rec.labels['activities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema, find_peaks\n",
    "def centered_moving_average(data, window_size):\n",
    "    ret = np.cumsum(data, dtype=float)\n",
    "    ret[window_size:] = ret[window_size:] - ret[:-window_size]\n",
    "    return ret[window_size - 1:] / window_size\n",
    "def plot_array(arr):\n",
    "    plt.figure(figsize=(25, 3))\n",
    "    plt.plot(arr)\n",
    "    plt.show()\n",
    "\n",
    "def windowed_peak_detection(data, window_size):\n",
    "    # Initialize an empty list to store the peaks\n",
    "    peaks = []\n",
    "\n",
    "    # Divide the data into windows\n",
    "    for i in range(0, len(data), window_size):\n",
    "        window = data[i:i + window_size]\n",
    "\n",
    "        # Compute the relative maxima of the window\n",
    "        window_peaks = argrelextrema(window, np.greater)\n",
    "\n",
    "        # Add the indices of the peaks to the list\n",
    "        peaks.extend(window_peaks[0] + i)\n",
    "\n",
    "    return np.array(peaks)\n",
    "\n",
    "def get_steps_from_peaks(data, peaks, threshold=1.25):\n",
    "    steps=0\n",
    "    for peak in peaks:\n",
    "        if data[peak]>threshold:\n",
    "            steps+=1\n",
    "    return steps\n",
    "\n",
    "def get_steps(data, window_size=80, threshold=1.25):\n",
    "    peaks, _ = find_peaks(data, height=1.25, distance=80)\n",
    "    steps = get_steps_from_peaks(data, peaks, threshold)\n",
    "    return steps\n",
    "\n",
    "with open('indices.txt', 'r') as f:\n",
    "    indices = [line.rstrip() for line in f]\n",
    "    \n",
    "\n",
    "def pad_arrays(arr_list):\n",
    "    max_len = max(len(arr) for arr in arr_list)\n",
    "    return [np.pad(arr, (0, max_len - len(arr)), 'constant') for arr in arr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.DataFrame(axs).to_csv('axs.csv')\\naxs = 0\\npd.DataFrame(ays).to_csv('ays.csv')\\nays = 0\\npd.DataFrame(azs).to_csv('azs.csv')\\nazs = 0\\npd.DataFrame(gxs).to_csv('gxs.csv')\\ngxs = 0\\npd.DataFrame(gys).to_csv('gys.csv')\\ngys = 0\\npd.DataFrame(gzs).to_csv('gzs.csv')\\ngzs = 0\\npd.DataFrame(mxs).to_csv('mxs.csv')\\nmxs = 0\\npd.DataFrame(mys).to_csv('mys.csv')\\nmys = 0\\npd.DataFrame(mzs).to_csv('mzs.csv')\\nmzs = 0\\npd.DataFrame(temps).to_csv('temps.csv')\\ntemps = 0\\npd.DataFrame(alts).to_csv('alts.csv')\\nalts = 0\\npd.DataFrame(paxs).to_csv('paxs.csv')\\npaxs = 0\\npd.DataFrame(pays).to_csv('pays.csv')\\npays = 0\\npd.DataFrame(pazs).to_csv('pazs.csv')\\npazs = 0\\npd.DataFrame(pgxs).to_csv('pgxs.csv')\\npgxs = 0\\npd.DataFrame(pgys).to_csv('pgys.csv')\\npgys = 0\\npd.DataFrame(pgzs).to_csv('pgzs.csv')\\npgzs = 0\\npd.DataFrame(pmxs).to_csv('pmxs.csv')\\npmxs = 0\\npd.DataFrame(pmys).to_csv('pmys.csv')\\npmys = 0\\npd.DataFrame(pmzs).to_csv('pmzs.csv')\\npmzs = 0\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''pd.DataFrame(axs).to_csv('axs.csv')\n",
    "axs = 0\n",
    "pd.DataFrame(ays).to_csv('ays.csv')\n",
    "ays = 0\n",
    "pd.DataFrame(azs).to_csv('azs.csv')\n",
    "azs = 0\n",
    "pd.DataFrame(gxs).to_csv('gxs.csv')\n",
    "gxs = 0\n",
    "pd.DataFrame(gys).to_csv('gys.csv')\n",
    "gys = 0\n",
    "pd.DataFrame(gzs).to_csv('gzs.csv')\n",
    "gzs = 0\n",
    "pd.DataFrame(mxs).to_csv('mxs.csv')\n",
    "mxs = 0\n",
    "pd.DataFrame(mys).to_csv('mys.csv')\n",
    "mys = 0\n",
    "pd.DataFrame(mzs).to_csv('mzs.csv')\n",
    "mzs = 0\n",
    "pd.DataFrame(temps).to_csv('temps.csv')\n",
    "temps = 0\n",
    "pd.DataFrame(alts).to_csv('alts.csv')\n",
    "alts = 0\n",
    "pd.DataFrame(paxs).to_csv('paxs.csv')\n",
    "paxs = 0\n",
    "pd.DataFrame(pays).to_csv('pays.csv')\n",
    "pays = 0\n",
    "pd.DataFrame(pazs).to_csv('pazs.csv')\n",
    "pazs = 0\n",
    "pd.DataFrame(pgxs).to_csv('pgxs.csv')\n",
    "pgxs = 0\n",
    "pd.DataFrame(pgys).to_csv('pgys.csv')\n",
    "pgys = 0\n",
    "pd.DataFrame(pgzs).to_csv('pgzs.csv')\n",
    "pgzs = 0\n",
    "pd.DataFrame(pmxs).to_csv('pmxs.csv')\n",
    "pmxs = 0\n",
    "pd.DataFrame(pmys).to_csv('pmys.csv')\n",
    "pmys = 0\n",
    "pd.DataFrame(pmzs).to_csv('pmzs.csv')\n",
    "pmzs = 0'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all filenames to process recordings\n",
    "filenames_test = []\n",
    "submission = []\n",
    "for filename in filenames_test:\n",
    "    recording = Recording(filename)\n",
    "    \n",
    "    # Assumes filename format ends with a three-digit ID before \".pkl\"\n",
    "    match = re.search(r'(\\d{3})\\.pkl$', filename)\n",
    "    if match:\n",
    "        id = int(match.group(1))\n",
    "        recording.id = id\n",
    "    else:\n",
    "        raise ValueError(f'Filename {filename} does not match expected format')\n",
    "\n",
    "    # Placeholder for the algorithm to process the recording\n",
    "    # Implement the logic to infer watch location, path index, step count,\n",
    "    # and activities (standing, walking, running, cycling) here.\n",
    "    # Ensure your algorithm is tolerant to missing data and does not crash\n",
    "    # when optional smartphone data traces are missing.\n",
    "\n",
    "    path_idx = 0  # Integer, path in {0, 1, 2, 3, 4}\n",
    "    watch_loc = 0  # Integer, 0: left wrist, 1: belt, 2: right ankle\n",
    "    standing = False  # Boolean, True if participant was standing still throughout the recording\n",
    "    walking = False  # Boolean, True if participant was walking throughout the recording\n",
    "    running = False  # Boolean, True if participant was running throughout the recording\n",
    "    cycling = False  # Boolean, True if participant was cycling throughout the recording\n",
    "    step_count = 0  # Integer, number of steps, must be provided for each recording\n",
    "\n",
    "    predictions = {\n",
    "        'Id': id, \n",
    "        'watch_loc': watch_loc, \n",
    "        'path_idx': path_idx,\n",
    "        'standing': standing,\n",
    "        'walking': walking,\n",
    "        'running': running,\n",
    "        'cycling': cycling,\n",
    "        'step_count': step_count\n",
    "        }\n",
    "\n",
    "    submission.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the predicted values into a .csv file to then upload the .csv file to Kaggle\n",
    "# When cross-checking the .csv file on your computer, we recommend using a text editor and NOT excel so that the results are displayed correctly\n",
    "# IMPORTANT: Do NOT change the name of the columns of the .csv file (\"Id\", \"watch_loc\", \"path_idx\", \"standing\", \"walking\", \"running\", \"cycling\", \"step_count\")\n",
    "submission_df = pd.DataFrame(submission, columns=['Id', 'watch_loc', 'path_idx', 'standing', 'walking', 'running', 'cycling', 'step_count'])\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(pad_arrays(alts))\n",
    "y = np.array(path_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 1 4 4 1 2 3 4 4 3 2 3 2 0 1 4 3 1 3 2 4 0 2 3 4 0 2 3 2 3 1 4 2 3 0 2\n",
      " 2 2 4 3 4 3 2 1 3 2 4 3 1 1 4 1 0 1 0 4 3 1 2 0 4 4 3 1 4 0 4 4 0 0 2 2 1\n",
      " 1 4 4 0 4 2]\n",
      "B_Accuracy: 66.13%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=5)\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(\"B_Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
