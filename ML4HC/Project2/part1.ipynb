{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from tsfresh import extract_features, select_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_array(array, color='blue'):\n",
    "    if not color == 'blue':\n",
    "        if color == 1:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.plot(array, color=color)\n",
    "    plt.show()\n",
    "\n",
    "def append_zero_to_each_row(arr):\n",
    "    zeros = np.zeros((arr.shape[0], 1))\n",
    "    return np.hstack((arr, zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11640, 187)\n",
      "(11640, 188)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/ptbdb_train.csv')\n",
    "df_test = pd.read_csv('data/ptbdb_test.csv')\n",
    "X_train = df_train.iloc[:, :-1].values\n",
    "y_train = df_train.iloc[:, -1].values\n",
    "X_test = df_test.iloc[:, :-1].values\n",
    "y_test = df_test.iloc[:, -1].values\n",
    "print(X_train.shape)\n",
    "X_train = append_zero_to_each_row(X_train)\n",
    "X_test = append_zero_to_each_row(X_test)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMcAAADFCAYAAABQFJVPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBfElEQVR4nO3deXhU9dn/8c8kZEEhQQhkKasY2bUQtoCgdYmiuC9YLWpFFJcKUqulal0rtW64ofgrij4q8CggWrESq7IU3FgUAREESYQEZEtYs57fH/dzMpkkhExIMjOZ9+u65prJyZnJN3By5szn3N/7eBzHcQQAAAAAAACEoYhADwAAAAAAAAAIFMIxAAAAAAAAhC3CMQAAAAAAAIQtwjEAAAAAAACELcIxAAAAAAAAhC3CMQAAAAAAAIQtwjEAAAAAAACErSaBHkBdKS0t1datW9W8eXN5PJ5ADwcAAAAAAAAB4jiO9u7dq5SUFEVEVF8b1mjCsa1bt6pdu3aBHgYAAAAAAACCRHZ2ttq2bVvtOo0mHGvevLkk+6Xj4uICPBoAAAAAAAAESn5+vtq1a1eWF1Wn0YRj7lTKuLg4wjEAAAAAAADUqPUWDfkBAAAAAAAQtvwOxxYuXKjzzz9fKSkp8ng8evfdd4/4nAULFigtLU2xsbE6/vjj9dJLL1VaZ9asWerevbtiYmLUvXt3zZkzx9+hAQAAAAAAAH7xOxzbv3+/Tj75ZD3//PM1Wn/Tpk0699xzNWTIEK1YsUJ/+ctfdPvtt2vWrFll6yxdulQjRozQyJEj9c0332jkyJG64oor9MUXX/g7PAAAAAAAAKDGPI7jOLV+ssejOXPm6KKLLjrsOnfffbfee+89rV27tmzZmDFj9M0332jp0qWSpBEjRig/P18ffvhh2TrnnHOOjjvuOE2fPr3K1y0oKFBBQUHZ126jtby8PHqOAQAAAPVt4ULpueekp5+WjnAVMAAAGlp+fr7i4+NrlBPVe8+xpUuXKiMjw2fZ2Wefra+//lpFRUXVrrNkyZLDvu7EiRMVHx9fdmvXrl3dDx4AAABA1Z5+WnrnHem11wI9EgAAjkq9h2O5ublKTEz0WZaYmKji4mLt2LGj2nVyc3MP+7oTJkxQXl5e2S07O7vuBw8AAACgaps32/133wV2HAAAHKUmDfFDKl42053JWX55VetUd7nNmJgYxcTE1OEoAQAAANSYe3KacAwAEOLqvXIsKSmpUgXY9u3b1aRJE7Vq1aradSpWkwEAAAAIAocOSf83C0Tffy8VFgZ2PAAAHIV6D8fS09OVmZnps2z+/Pnq27evoqKiql1n0KBB9T08AAAAAP76+Wfv4+Ji6YcfAjcWAACOkt/h2L59+7Ry5UqtXLlSkrRp0yatXLlSWVlZkqwX2DXXXFO2/pgxY7R582aNHz9ea9eu1SuvvKKpU6fqzjvvLFtn7Nixmj9/vh577DF9//33euyxx/Txxx9r3LhxR/fbhbLiYikrS9q6NdAjAQAAAHxV7PfL1EoAQAjzOxz7+uuv1bt3b/Xu3VuSNH78ePXu3Vt//etfJUk5OTllQZkkderUSfPmzdNnn32mX//613r44Yf17LPP6tJLLy1bZ9CgQZoxY4ZeffVVnXTSSZo2bZpmzpypAQMGHO3vF7ruuUfq0EH6xz8CPRIAAADAF+EYAKAR8bsh/2mnnVbWUL8q06ZNq7Ts1FNP1fLly6t93csuu0yXXXaZv8NpvNq1s/vyJesAAABAMHDDschIqaSEcAwAENLqvecYaqltW7uveFYOAAAACDT3GDU93e4JxwAAIYxwLFi54RiVYwAAAAg2bjg2bJjdb9wo7d8fuPEAAHAUCMeClTutMidHKioK7FgAAACA8txwrE8fqU0byXGktWsDOyYAAGqJcCxYtW4tRUXZgUZOTqBHAwAAAHi5sxvatZN69rTHq1YFbjwAABwFwrFgFREh/epX9piplQAAAAgW+/dLu3fb4/LhGH3HAAAhinAsmHHFSgAAAAQbd0plXJzdCMcAACGOcCyYccVKAAAABBv32NQ9kUs4BgAIcYRjwYwrVgIAACDYuOGYe6zao4fdb90q7doVmDEBAHAUCMeCGeEYAAAAgk3FyrG4OKlDB3u8enVgxgQAwFEgHAtm9BwDAABAsKkYjklMrQQAhDTCsWBGzzEAAAAEG8IxAEAjQzgWzNxwLCdHKi4O7FgAAAAAqfpwbNWqhh8PAABHiXAsmCUmSk2aSKWlUm5uoEcDAAAAeFt+HK5yzHEafkwAABwFwrFgFhEh/epX9piplQAAAAi0vDxp7157XD4c69rVjl1377ZZDwAAhBDCsWDHFSsBAAAQLNwTti1bSscc410eGyulptpj+o4BAEIM4Viw44qVAAAACBZV9Rtz0ZQfABCiCMeCHVesBAAAQLBwj0ndY9TyevWye8IxAECIIRwLdkyrBAAAQLCgcgwA0AgRjgU7plUCAAAgWNQkHFu92q62DgBAiCAcC3ZUjgEAACBYVBeOde4sxcRIBw5ImzY17LgAADgKhGPBzg3Htm6VSkoCOxYAAACEN/eEbVXhWJMmUrdu9piplQCAEEI4FuwSE+1Ao6REys0N9GgAAAAQrhyn+soxib5jAICQRDgW7CIjpZQUe8zUSgAAAATKrl3SwYP2uKqrVUqEYwCAkEQ4Fgrcgw/3TB0AAADQ0Nxj0TZtrLdYVQjHAAAhqFbh2OTJk9WpUyfFxsYqLS1NixYtOuy61113nTweT6Vbjx49ytaZNm1alescOnSoNsNrfLhiJQAAAALNDccOVzUmSb162f3330uFhfU/JgAA6oDf4djMmTM1btw43XPPPVqxYoWGDBmiYcOGKSsrq8r1n3nmGeXk5JTdsrOz1bJlS11++eU+68XFxfmsl5OTo9jY2Nr9Vo0NV6wEAABAoB2p35j7vehoqbiYfrkAgJDhdzj21FNPadSoUbrhhhvUrVs3TZo0Se3atdOLL75Y5frx8fFKSkoqu3399dfavXu3fv/73/us5/F4fNZLSkqqdhwFBQXKz8/3uTVaTKsEAABAoNUkHPN4pIQEe7xjR/2PCQCAOuBXOFZYWKhly5YpIyPDZ3lGRoaWLFlSo9eYOnWqzjzzTHXo0MFn+b59+9ShQwe1bdtWw4cP14oVK6p9nYkTJyo+Pr7s1q66N+lQx7RKAAAABFpNwjGJcAwAEHL8Csd27NihkpISJSYm+ixPTExUbg3KpnNycvThhx/qhhtu8FnetWtXTZs2Te+9956mT5+u2NhYDR48WOvXrz/sa02YMEF5eXllt+zGXFXFtEoAAAAEmr/h2C+/1O94AACoI01q8ySPx+PzteM4lZZVZdq0aWrRooUuuugin+UDBw7UwIEDy74ePHiw+vTpo+eee07PPvtsla8VExOjmMNdJaexccOxLVukkhIpMjKw4wEAAED4cU/UHikca93a7qkcAwCECL8qxxISEhQZGVmpSmz79u2VqskqchxHr7zyikaOHKno6OjqBxURoX79+lVbORZWkpIsECspkbZtC/RoAAAAEG5KS2sejjGtEgAQYvwKx6Kjo5WWlqbMzEyf5ZmZmRo0aFC1z12wYIE2bNigUaNGHfHnOI6jlStXKjk52Z/hNV6RkVJKij1maiUAAAAa2i+/SIWF1nDfPS49HKZVAgBCjN9Xqxw/frz++c9/6pVXXtHatWt1xx13KCsrS2PGjJFkvcCuueaaSs+bOnWqBgwYoJ49e1b63oMPPqiPPvpIGzdu1MqVKzVq1CitXLmy7DUh+o4BAAAgcNx+Y0lJUlRU9etSOQYACDF+9xwbMWKEdu7cqYceekg5OTnq2bOn5s2bV3b1yZycHGVlZfk8Jy8vT7NmzdIzzzxT5Wvu2bNHN954o3JzcxUfH6/evXtr4cKF6t+/fy1+pUbKDcca84UHAAAAEJxq2oxfoucYACDk1Koh/y233KJbbrmlyu9Nmzat0rL4+HgdOHDgsK/39NNP6+mnn67NUMKHeyBC5RgAAAAamj/hGJVjAIAQ4/e0SgQI0yoBAAAQKLUJx+g5BgAIEYRjoYJplQAAAAiU2oRjO3faVS4BAAhyhGOhgmmVAAAACJTahGMlJVJeXv2NCQCAOkI4FircyrEtWzgDBwAAgIblnqCtSTgWEyM1b26P6TsGAAgBhGOhIilJioiQioulbdsCPRoAAACEi5ISO0Er1Swck+g7BgAIKYRjoaJJEyklxR4ztRIAAAANJTfXArLISDthWxNcsRIAEEIIx0IJV6wEAABAQ3P7jaWkWEBWE61b2z3hGAAgBBCOhRLCMQAAADQ0f5rxu6gcAwCEEMKxUOIekLgHKAAAAEB9c48927ev+XPoOQYACCGEY6GEyjEAAAA0tKwsu6dyDADQSBGOhRLCMQAAADS02lSO0XMMABBCCMdCCdMqAQAA0NCoHAMANHKEY6HErRzbskUqLQ3sWAAAABAe6DkGAGjkCMdCSXKyFBEhFRVxoAEAAID6V1Agbdtmj/2pHGNaJQAghBCOhZImTSwgk5haCQAAgPrn9rpt2lRq1armz3Mrx/Ly7MQuAABBjHAs1KSk2H1ubmDHAQAAgMavfL8xj6fmz2vRwmY8SNLOnXU+LAAA6hLhWKhxS9S3bw/sOAAAAND41abfmCRFRkotW9pj2oEAAIIc4VioadPG7gnHAAAAUN/ccMyffmMu+o4BAEIE4VioIRwDAABAQ3GnVfpbOSZ5+44RjgEAghzhWKghHAMAAEBDOZrKMcIxAECIIBwLNYRjAAAAaCh1UTlGzzEAQJAjHAs1hGMAAABoKPQcAwCEAcKxUOOGY5yBAwAAQH3Ky5Py8+0x0yoBAI0Y4VioKV855jiBHQsAAAAaL7dqrGVL6dhj/X8+4RgAIETUKhybPHmyOnXqpNjYWKWlpWnRokWHXfezzz6Tx+OpdPv+++991ps1a5a6d++umJgYde/eXXPmzKnN0Bo/tzy9uFjasyegQwEAAEAj5vYbq03VmETPMQBAyPA7HJs5c6bGjRune+65RytWrNCQIUM0bNgwZblvnoexbt065eTklN1SU1PLvrd06VKNGDFCI0eO1DfffKORI0fqiiuu0BdffOH/b9TYRUdLLVrYY/qOAQAAoL64lWO1acYv0XMMABAy/A7HnnrqKY0aNUo33HCDunXrpkmTJqldu3Z68cUXq31emzZtlJSUVHaLjIws+96kSZN01llnacKECeratasmTJigM844Q5MmTTrs6xUUFCg/P9/nFjbcAw3CMQAAANSXuqoc27GDdiAAgKDmVzhWWFioZcuWKSMjw2d5RkaGlixZUu1ze/fureTkZJ1xxhn69NNPfb63dOnSSq959tlnV/uaEydOVHx8fNmtXW3ftEMRV6wEAABAfTvayjE3HDt0SDpwoG7GBABAPfArHNuxY4dKSkqUmJjoszwxMVG5ublVPic5OVkvv/yyZs2apdmzZ6tLly4644wztHDhwrJ1cnNz/XpNSZowYYLy8vLKbtnum3c4IBwDAABAfXOPr2t7EvrYY6WYGHtM3zEAQBBrUpsneTwen68dx6m0zNWlSxd16dKl7Ov09HRlZ2friSee0NChQ2v1mpIUExOjGPfNNtwQjgEAAKC+udMqa1s55vFYO5Cff7aplR071tnQAACoS35VjiUkJCgyMrJSRdf27dsrVX5VZ+DAgVq/fn3Z10lJSUf9mmGFcAwAAAD1qbTUQi2p9pVjkm/fMQAAgpRf4Vh0dLTS0tKUmZnpszwzM1ODBg2q8eusWLFCycnJZV+np6dXes358+f79ZphhXAMAAAA9Wn7dqmwUIqIkFJSav86hGMAgBDg97TK8ePHa+TIkerbt6/S09P18ssvKysrS2PGjJFkvcC2bNmi119/XZJdibJjx47q0aOHCgsL9cYbb2jWrFmaNWtW2WuOHTtWQ4cO1WOPPaYLL7xQc+fO1ccff6zFixfX0a/ZyBCOAQAAoD65/caSk6WoqNq/jhuO0XMMABDE/A7HRowYoZ07d+qhhx5STk6OevbsqXnz5qlDhw6SpJycHGW5/QlkV7i88847tWXLFjVt2lQ9evTQBx98oHPPPbdsnUGDBmnGjBm69957dd9996lz586aOXOmBgwYUAe/YiPkhmMcZAAAAKA+HG2/MVfr1nZP5RgAIIh5HMdxAj2IupCfn6/4+Hjl5eUpLi4u0MOpX2vWSD16SK1acaABAACAujdpknTHHdIVV0gzZ9b+dR56SLr/funGG6UpU+pseAAAHIk/OZFfPccQJNzKsZ07peLiwI4FAAAAjU9dVY7RcwwAEAIIx0JRy5bWHFXiQAMAAAB1z+05djRXqpS80yppBwIACGKEY6EoIsJ7Fo6m/AAAAKhrVI4BAMII4Vio4oqVAAAAqC91VTlGOAYACAGEY6GKcAwAAAD1obBQys21x3VVObZzp1RaenSvBQBAPSEcC1WEYwAAAKgPW7ZIjiPFxnrDrdpyn19aKu3effRjAwCgHhCOhSrCMQAAANSH8lMqPZ6je62oKCk+3h4ztRIAEKQIx0IV4RgAAADqg9uM/2j7jbnoOwYACHKEY6GKcAwAAAD1oa6a8bsIxwAAQY5wLFS54dgvvwR2HAAAAGhc3Mqxo23G72rd2u45bgUABCnCsVBF5RgAAADqA5VjAIAwQzgWqgjHAAAAUB/qunKMcAwAEOQIx0KVW56+b5904EBgxwIAAIDGg8oxAECYIRwLVc2bSzEx9pj+DQAAAKgLe/dKe/bY47oKx+g5BgAIcoRjocrjYWolAAAA6pZbNdaihZ2MrQtUjgEAghzhWCgjHAMAAEBdcsOxuuo3JhGOAQCCHuFYKCMcAwAAQF1ym/HX1ZRKiXAMABD0CMdCGeEYAAAA6lJ9VI65Pcfy86WCgrp7XQAA6gjhWCgjHAMAAEBdqo/Ksfh4KTLSHu/cWXevCwBAHSEcC2VuOMaVfwAAAFAX6qNyLCJCatXKHjO1EgAQhAjHQhmVYwAAAKhL9VE5JnmnVhKOAQCCEOFYKCMcAwAAQF05eNAbjnXoULev7TblZ8YDACAIEY6FMvcMHOEYAAAAjtbSpVJhoZSSUrfTKiWuWAkACGqEY6GsfOWY4wR2LAAAAAhtn3xi96efLnk8dfvahGMAgCBWq3Bs8uTJ6tSpk2JjY5WWlqZFixYddt3Zs2frrLPOUuvWrRUXF6f09HR99NFHPutMmzZNHo+n0u3QoUO1GV74cCvHioqkvLzAjgUAAAChrXw4Vtfc41amVQIAgpDf4djMmTM1btw43XPPPVqxYoWGDBmiYcOGKcvtT1DBwoULddZZZ2nevHlatmyZfvOb3+j888/XihUrfNaLi4tTTk6Ozy02NrZ2v1W4iI2V4uLsMVMrAQAAUFt790pffmmP6yMco+cYACCI+R2OPfXUUxo1apRuuOEGdevWTZMmTVK7du304osvVrn+pEmTdNddd6lfv35KTU3Vo48+qtTUVL3//vs+63k8HiUlJfncqlNQUKD8/HyfW1iiKT8AAACO1qJFUkmJdPzxdd+MX/K+5uzZ0qRJtAQBAAQVv8KxwsJCLVu2TBkZGT7LMzIytGTJkhq9Rmlpqfbu3auWLVv6LN+3b586dOigtm3bavjw4ZUqyyqaOHGi4uPjy27t6vpy06GCcAwAAABH69NP7b4+qsYkafhw6corpeJi6Y47pBEjrFoNAIAg4Fc4tmPHDpWUlCgxMdFneWJionJzc2v0Gk8++aT279+vK664omxZ165dNW3aNL333nuaPn26YmNjNXjwYK1fv/6wrzNhwgTl5eWV3bKzs/35VRoPwjEAAAAcrfrsNyZJTZpIb70lPfusPX77balfP2nNmvr5eQAA+KFJbZ7kqXD1GsdxKi2ryvTp0/XAAw9o7ty5auOGOpIGDhyogQMHln09ePBg9enTR88995yeffbZKl8rJiZGMTExtRl+40I4hsamtFR64w3p8celqCipWze7de9u9yecYMsBAEDd2LVLcmdt/OY39fdzPB7pD3+Q+vaVLr9cWrdO6t9f+uc/raoMoclxrCKQ4zMAIcyvcCwhIUGRkZGVqsS2b99eqZqsopkzZ2rUqFF6++23deaZZ1a7bkREhPr161dt5Rj+jxuO0dwUjcHKldKtt0rlp2lXnGJ9zDHShAnSXXdJ0dENOjwAABqlBQss4OjWTTpC3986kZ4uLV8u/fa3VrH2299aNdlll9X/z8bRcxxp40b7v3Nvu3ZZ37pyBQ8AEEr8mlYZHR2ttLQ0ZWZm+izPzMzUoEGDDvu86dOn67rrrtNbb72l884774g/x3EcrVy5UsnJyf4MLzxROYbGYPduC8XS0iwYO/ZYaeJE6d137f6aa+wsc7Nm0oED0n33Sb17S4sXB3rkAACEvvqeUlmVNm2k+fOlm2+2r8ePt/d4BK9Vq6TRo6WOHa2S/8YbpRkz7HNIcbE0d26gRwgAteb3tMrx48dr5MiR6tu3r9LT0/Xyyy8rKytLY8aMkWS9wLZs2aLXX39dkgVj11xzjZ555hkNHDiwrOqsadOmio+PlyQ9+OCDGjhwoFJTU5Wfn69nn31WK1eu1AsvvFBXv2fj1bq13ROOIdQ4jvT999IHH0iPPSbt2GHLR4yQnnhCatvWvr7wQt/nTJ8ujRtnPUqGDLEDs7//XTruuAb/FQAAaBQCEY5JUmSk9OST0rx50ubN1lLh/vsbdgw4sq++kv72N9/wKyrKqsROP92qxp57Tvr228CNEQCOkl+VY5I0YsQITZo0SQ899JB+/etfa+HChZo3b546/N/lmXNycpSVlVW2/pQpU1RcXKxbb71VycnJZbexY8eWrbNnzx7deOON6tatmzIyMrRlyxYtXLhQ/fv3r4NfsZGjcgyhZOdOaeZMadQoqX176yP2pz9ZMNa9u/Sf/9gZSDcYq8jjka66ykK166+3ZS+/bNNA3nmn4X4PAAAai9xcO+Hk8UinntrwP79pUzspJtnJsnKfIxBgixZJ55xjfeHmzrVt5IorpH//26r+Fy6UHnjATmxKhGMAQprHcRwn0IOoC/n5+YqPj1deXp7i4uICPZyG8913Uq9eUkICfccQXHbutH5hy5d779evt+ovV0yMNHSodPHF0g03+N/IdcEC6aabrKGvJN1+ux1g0xAWAICamT7dTjz17m3v1YHgOHYhgAULLGiZMSMw44BZvVoaO9ZOWkpW4Xf11dbztWvXyuvn5UktWtjjnTulli0bbKgAUB1/ciK/K8cQZNzKsZ07ba4/EGgff2xVYAkJ0llnSXffbQe5P/xgB7+9ekl//KP00Ud21tHtN1KbQOvUU6VvvrGDNckuD3/GGXYWHAAAHFmgplSW5/FIzzwjRURYhfnChf4933GkkpL6GVs4yc+33m8nn2zBWHS0nYT84QfptdeqDsYkKT7e+pBJVI8BCFmEY6GuVSs7oHAcC8iAQDlwwCq3zjpLWrvWlnXubJdqf/RRK8Hfts0Omp54QsrIsKkURysmxl5/7lwpLs6mAKSlSUuXHv1rAwDQ2AVDOCZZIHPjjfZ47Ngjh10FBXZsccstUrt2UmysVaFv2lT/Y21sHEd64w2pSxfp6aft3/6ii6wy/6WXpOOPP/JrnHSS3ROOAQhRhGOhLjLSKnQk+o4hcL7+WurTx5qxSnagumuXtGGD9L//a5VdZ5/trXSsDxdcIH35pVWtbd1qVWUvveQ7jRMAAHj99JO0caMdTw4ZEujRSA89ZNPzVq6Upk6t/P28PAtxLr/cjn+HDZNefFHassVmUEydKp14IiHZkZSU2L/P/PnSCy/YMdPIkVZ5n5oqffihNGeOtxqsJk4+2e4JxwCEKL+vVokg1KaN9RsjHENDKy62qq2HH7bHycnSq69aEBYIXbpIn39uzfrfecemay5aZAd+bi8MAEDwKS2VfvxRWrbM+l6lpEhjxlg1EOrPp5/aff/+UvPmgR2LZFdhf+ABuyr1PfdY8/fISOn992265b//LRUWetdPTraTYxdcIDVrZldUnD/fQrLXXpOuvVa64w47cebxBOq3ahjFxXaScP58u2Vn299P+VtMjJ1A/PFH339HSTrmGOnee21aZUyM/z+fyjEAIY6G/I3B6afbwc1bb0m//W2gR4NwsHu39D//Y5VZ7hTKyy+3s7etWgV2bJJViz35pPU7Ky21q1++9lrgp4wAAGwfvXGjVR0vW2b3y5dbVVB5qan2PsO+u/5cc429n99zj/TII4EejSkqsiqktWvtatSbNkmHDnm/37WrdOml0oUXWhuFiAoTYZYskR580AIiV3KybUfuzZ+KKH8cOmQXy8rJ8b3l5lr4mJpqlW2pqXaLi7PjlJ077ST3tm12q+rx9u3WjiI52W5JSXYfHW0XMvjPfyr/DVUnOtraX6SmWnh48812JfHa+uEHO0nZtKm0d6+FmgAQYP7kRIRjjcGVV9rZtEmTrEcDUB8cx6qypkyxqZIHD9ry+HirzLrqquA7K/v55zZNYMMG+3rcOKt0q4teZwAAX44jvfuuhV1upUrTpnbfpIn0/ffeQGzPnsrPj4mRfv1rC0bef99CBcmqf554wttGAnXDcaxX15YtFqwEUwg5f75vFXpqql3FcsQIqUePmh1vLF1q7/mZmdafrLyOHaWBA+0KnX362P3RnNwrKJBeftkq17Ztq/nzWrSwIKmuLiZw3HHW+zUjwyq5ioossDt0yI7bDh2yGSepqfZ/X5cBVkmJBYAHD1qvshNPrLvXBoBaIhwLt3Ds9tut11MwnfVD6HIcaccOO6u/aZP39vnn0qpV3vV69rQrGP3ud8E9ZXH/fulPf7KqNsnOQr/xhh0MAwDqxq5d9p7wzjs1Wz862kKwvn2t+qdvX6teca9cnJcn/eUvtu92HAsunnrKTnjU9kTMvn3WR+k3v7GK4nDnVvrExFhFeLCdOHrxRQtIL7nEtpXa/r8fOmRB2Sef2O2LL6oOo9q3t0DHcSxUKi723jp0sMDp7LOlTp28zykqkqZNs/YS2dm2rFUrW6d8dVdSkgXC69d7bxVDtJYtpcREC68SEys/bt3agie3Es2tSsvPlwYMsPGlpQW2Yqt/f+mrr+wk6uWXB24cAPB/CMfCLRx7+GHpr3+VRo+2s1ZAbRw8aAeijz9uB11ViY21/h833SSlpwdfpVh1PvzQepHl5loFw/jx9ndz7LGBHhkAhLZPPrHpeVu22P71d7+z8Kt8tUpBgQUGbhDWo4etcyRLl9oVDL/7zr7u1ct7YiY+vuZjfP996dZbLcCIi7Nq++uuC633sbr20ks2le6007y9x8LB3r029XL5cmnFCrv/8ceaP/+EEyyIOvFEOzntPjclRbrvPjvWqMm2nZ8v/fyznWBMSKjZc4Ld6NHSP/9pvcsefjjQowEAwrGwC8emTLGmtRdeaNMZAH8UFtqBzCOPeKeweDzSr35l0w46dbLbCSdI551nZzZD1Y4ddiXNt9+2r9u3l5591v52AKCxKS21it/iYm/lSU0bbeflWfPzuXNtyl2bNt5+Taeeah/oCwrsQ/ATT9hzTjxRevNNC7/qUlGR9ZF8+GHpwAFbdswx1lbippukfv0OH3Jt3WoV9rNm2dexsd7+VcOH20nF5OS6HW+oGDJEWrzY/l3vvTfQowmsvDy7QmZWlgW85W8REfa9+fMtVCsu9n1u69ZW5XjTTcFXfdfQnnvO/t4uuMD2HQAQYIRj4RaOzZljJefp6famDdREQYFdxOHBB6XNm21Z+/bS/fdb/7DGfIWw99+X/vAH7+99/vkWktVXg14AaCgHD1ol19y5tq+rWAncokXVU7bcx9nZ0nvvSZ99VjkEcEVE2NT0gwel1att2Y032rTH+qzGdS8GM2WKtGaNd3nPnhbIdetmUzO7dbP3s//3/6QJE6xCJzJSuvNOa0Hx4otW4VNYaD2ann/eLmjk8Vj4tnq1hYpr11ovKvd7jcnixRaORUdb64SUlECPKDTk59vfxvz5to2cc44dTzRrFuiRBYcFC6wSsWNH264AIMAIx8ItHPvvf6VTTrEznxs3Nu5QAzWzb59vX4uNG+0qR7/8YtVTv/xiB3iu5GQ7azxqVO0u3x2K9u+3arknnrAPgE2b2pnfceM4yAUQvH76yaaJHzjg2xOpqMhCnfnzvdVVku3P4uLsPeBwYdfhdO1qlbXnnmvvG//5jwVv69Z512nVSpo6tWErcB3Hjn2mTLFK4IrN1iULw9y+Uv37W4XYySd7v//dd9bof/ly+3rAAOubtmGDvX55I0faz2pMVUHnnSfNm0dLDtStXbu8FzbYs8e/qc8AUA8Ix8ItHNuzxxqF5ufbwenbb3sb2qLxKy2VvvnGPhB9/LEd8B+uZ1hFbdpId99tPUca00G/P9assamWCxbY161bW6XBzTcTNAMIDsXF0r/+ZQHNRx9VDm8qatvWpjVdeKFNgYyJsfeK3bstJNu2zXsr//X27fZecN559vzDXW1uyxbrUZWTY72/AjktcedOC+zWrvXe1q2zqZPNm9vVCm++ueom5UVF0sSJNq2wfHDYurVd6a9tW7uAS0mJ9UqbM8eu8BfqVq60iriICPu3OuGEQI8IjUm7dtZLbfFiafDgQI8GQJgjHAu3cEyyEu9zzrGzp7/7nfTaa3bQg8antNQqwZYssUAsM9M+0FSUkGAfbFJTpc6d7UpJrVvbLSHB7lu0YDuR7IPmjBk2zcZtrPurX1k1XU0b6wKAZFMN58+3MMtxrIF8r14WtiQk+PdamzdLr7xifSG3bvUuP/VUmzZYsTdSmzZW5dW7d+ObBuiPkhLrHZWQYAHZkaxeLS1aZCFRr142vdT16ad21b2dO+198513pKFD62/sDeHKK6WZM+1++vRAjwaNjVuV+MILdvIRAAKIcCwcwzHJDsQvvtjOft58s70phfPBcWOwd6+0bJn07bd2W7XKDuL37/ddr1kzuzR9RoZNDUlNteAL/ikqsmD5oYe8l2Tv2NGa7F5yyeGrKACEt7177cPgrFl2X3Ef7UpKspDMDct69bL+WG6V6o4ddrLrk09sCuMPP3ifm5Ag/f731tuLSp+G9dNPdny1cqWFkJMmWVXevn32f79vn92aNbPgrKoqtWCxYYPUpYudaFu50neqKVAX/vIXq8i86Sa7IioABBDhWLiGY5JVv1x1lZ2tnjDBphMgeBw8KP3jH9LChXbWPzXVW911wgk2rWXJErstXWqBWGlp5deJibEPVmedJZ19tjRwINVNdamgwBo5/+1vvlNUe/a0kOzSS+1DbaDCZ8ex6Uzr19v2MWhQ+PSKA4LFrl3WuH72bKsUK9/3ql0721fExXlPbGzcWPXrREba+0BUlK1bnsdjVWI33WThDH/ngXPggPXlnDGj+vWOP94atF9/vf3/Hy3HserwuLiatT84cMAuNHC4E2Q33mjvb+eeK33wwdGPD6hoxgy7iAUXCgMQBAjHwjkck6yx6k032eO//916SiHw5s2TbrvN/6v3tG9vU2TKVxqccIKdvUb9OnBAevNNm0bzySe+PWk6drRQqn9/qV8/+z+qyQeX0lLrw/HWW7Yt9Oljr5OeXnnKVVGR9YP59lurGPzhBwvENmzwrUxp1sxCUrdxttsMF2gMdu2SvvhCOuYY6wHVtq1vSFRSYn2mvvzSbl9/bUHTKadYFc8pp9gVCY+G49jf4y+/2BUgZ8+26Xbl9wmpqRacX3KJXTmxYni+d6/3KoirVnlDs127fNfr2VM6/XS7DR169GNH3XEcu4jLgw9aGNq8ue1/mzWzx+vXW183yZZdf70FZf5U+u3ZY9uwuz1/+aWdDGna1KrDL7hAGj7cptC6cnJsu3zvPes9GhFhAdjVV/u+9pYtFt4VFto00lNOOep/EqCSNWukHj3sbyAvj/YdAAKKcCzcwzFJevxx6a677PEbb1Q+QELDyc6Wxo61Rr6SfbC76y47AHbDjvXr7QNSVJQ1/XXDkvR0632FwNu92/uh+KOPrNlzeU2a2Ifa3r1tmlT37nbfoYNVhnz7rQVi06dbL5yqpKba/3lJiX1oXrvWPpBXJTLSAroDB+yDkSsiwj7wpKX59pdr3dqmdB1/fGhMty4qsn+Db76xsK9bNxt7ME9Xqk9u9ciOHXYFwcb873DokFUbZGbaB/1lyyo3oG/TxqqzYmNtatjhpjFKtr336mWNoSMjbd+7Z4/9Te/ZY9PhKnIcC74OHrTxHDpUdRP8k07yVpP26OH/35ZbBfrtt/a3PHiwb78rBKfSUvu/rvj/vX+/HXM984ztvyVb54QTLDxzw7TmzS3s2rvXd1vcvbtyWFoVj8feKwYOtJMtX35Z9Xpjx9rxoHuRpj/+UXrqKWnIEKtgB+pDcbF07LEWwv74o713A0CAEI4Rjpk//1l67DH7UPzDD/SgamiFhXaA/OCDdsAcGSndcYd0//12cFzR7t12sMwVEoPfvn3Sf/8rffWV98z+tm1Vrxsba3+Dbg8zyabHXHqpVZcsW2ZTaN0PUhU1b+5t6N2li3cqbseONpXWcew13ntPmju38rSsijp29H6YHzgwOM7oFhZaNdyKFd5/zxUrfKepSfb7duliQdkJJ9jfUWys9+8mNtbCiu7dA/N71JXt2+33X73ae/W9NWu8FSkDBkivvmr/Do2B2/vo44/ttmhR5fA5NdXus7Mrf0+ybaFvX6vi7NfP1lm0yAKAdevqdrz9+3srxOj9hao4jm3LkyZZ1bi/Onf2ViX37y/9+te2j5w71/b1y5ZVfk7//lY9PHy4XbX8kUds+ZAh0v/+rwVkHTrY8ci8edKwYUfzGwLV69PH3sfmzJEuuijQowEQxgjHCMdMUZE1Wl27Vho3Tnr66UCPKDw4jk3DmzDBe+XDU06RJk+2gAONj+PYZcu//FL67jsLMtautQ/lhYW2TnS0XcHpqqvsvuIUzF27pM8/t+lj0dHeKbQdOvhXjfLTT/bB56efbArYL79YtdEvv9iUmvKBU3KyHbSecYaF525FgztN6Ljj6r7KbPduG9+aNd5/pw0brFquohYt7EPhnj3S999XHYpU5PFIY8ZYv7hQmI62a5cFOCtWSMuX2/2WLVWv6/HYB9zCQptW+MAD0p13ht4U6/x8+9tYscIChE8+sSsBlpecLJ15pt3OOMNbQes4tm52tv3N7d1r20iXLoevptu2zYKyr76yf6vjjrNbixZ236xZ1dt5VJQ3dHVvTZvS9wv+ycqyq46Wb96/d69VCjZv7rsttmhh2/6R9l0//2yVzMuXWyg2fLg9r7y5c6VrrrG/t5QUm6I7Y4b9vSxfHhoVxAhdv/+9NG2avU/df3+gRwMgjBGOEY55ZWZaj4omTWx6UqhXVAS7xYvtw+oXX9jXiYl2xZ5rrw2OCh00rJIS6yu2ebOdRQ10WHPggPTvf9vU0Pfftw9N1WnWzKbwuVNEu3Wzr5OSrPrNnw9Xu3dbFcWkSVX/3GbNLAx0KyX69bOqHPfvpqTE/h3dSqqffrKwrPy0tz17vM1/27Sx3kC/+13wfQgsLbVAaOpUO6tesULO47FKqZNO8p2ie+KJFgzddJO3GiUtzarIgi14d/+/vv/egjD39v33vhe5cDVvLp12mjcQ69Yt+P7fgFCzbp1VOK5Z4102Y4Y0YkTgxoTw8PTT0vjxtv3NmhXo0QAIY4RjhGO+LrrIziCeeaZdUYsPHEevuNj38u2//GJ9PObOte8fc4z0pz9Zf4/mzQM7VqAqBQUW0MyebdVu7rbsbtcVA5uKoqK8/cwSEuzCEW6wddJJ3qunVhWKdetmVQzlQ7df/apu9k2ffSbdcot3muqpp1rVZn2cGFi1yqpDzzijZn/n2dkWZL36qoV7rq5drX9Q794Wop50UvWv5zjS//yP9RPas8f+L8aMsX6GFaucOna04Myf6do7d1oV45IlVg154ID9jCZNfG9VLdu92wKwDRuq34aSkuz/3Q3E+vXz9kUCUHf27rULA7zzju1rvvuucfcsRHD4z39s337CCdZXFwAChHCMcMzXxo32wbCggLn/R2PrVgu85syxapWqRERIN9xgZeQVpzgAoaSgwPYd5XterV1rB7lVNTAvLzraO9Vt7lxvKNarl02vuPji+q2kLCyUnnxSevhh+1tt0sQuK3/11RZkVTcNsaTEQrrDja+kxKrunnnGgjjJwvArrpBGjbKG6uVDvs2bLYCcPdv61LlvufHxNsV21CgLxGoTDG7dKt18s/Ugqk5kpL0HuOFbjx4W8Fec5rVhgwViddWjKybGqt26dKl8i4+vm58B4MgcR1qwwFv5C9S3X36xCm6Px44Bquq1CwANgHCMcKyye++1HjydOtmH3IpVBI5jlw4/eNDWSUnhzKKruNgqT+691z5Alhcd7e3R1K+f9NBDjadJNnA4Bw96+5i59+vWeS9QUPFqaw0VilX000/S7bdbmOVKTLQpRVdfbX+zGzd6LwLw1VfWiyciwvo19unjDZTatrVqreees6myku0j27a1AMzVpYtVaZSU2FSSio2zTzvNArFLLrFQ7Wg5jgVvmZne6aXudNP9++3/ZccO/1+3SxfvVXMTEmw/6N6Kiny/Ln879lhvANa+Pe8jABCukpNtGv3nn9uFZAAgAAjHCMcq27/fPqxs2WJXMLrnHu/3liyx5vHlL+sdFWXTcTp1sg84VU13KS6u3PPn0CEL1nr18m0oHgz9tn74wa7kd8opNT9z+sUXVpmxYoV9PWCA9VHo0sUCMXfqGADjON7A6bvvrCfWRRcFdh+wZIn0xht2xbbyjd+bNj18FWh1jjvO+n7dcouFY0uWWP+wmTNtCmJ5ERF2tbhLLrFwsF27o/td/OU4tt9fscLb9P+HH6yqyw323fukJAvDBg60QAwAgNo6+2xr5/Lyy9Lo0YEeDYAwVe/h2OTJk/X4448rJydHPXr00KRJkzRkyJDDrr9gwQKNHz9eq1evVkpKiu666y6NGTPGZ51Zs2bpvvvu048//qjOnTvrb3/7my6++OIaj4lwrAamT7dpPMccYz1h8vIsJHOn5MTEWN+frCwLvupKs2YWlA0ebH2GBg9uuMbkJSXSv/4lvfCCVVZIVuI9eLB9WL3kEgvvXIWFNm1s7VprXP7KK/bh8rjjpL//3aZMBkPQB8B/RUV2oP7mm9K771owFh1t1WHlLwTgOBYiuVePXL7c9pfdu1ufr9/9ruqqr717LSCbPt1e9+KLLRhs06ahf1MAAALrrrukxx+Xbr1Vev75QI8GQJiq13Bs5syZGjlypCZPnqzBgwdrypQp+uc//6k1a9aoffv2ldbftGmTevbsqdGjR+umm27Sf//7X91yyy2aPn26Lr30UknS0qVLNWTIED388MO6+OKLNWfOHP31r3/V4sWLNaCGZbiEYzXgOBZOLV5sFWE//WTLIiJsGtD991sVRHGxVRps2mS3n3+2q6tVFBlplRflG0BHR9vrfvutNateu9YCp/I8HgvLhg6V+va1yrR27exnx8QcfvzFxVbxsGqV9/VXrbIArGtXb2Pv7t2teu2dd6QXX7Swz/25XbpYMFhe3772s9eutZ47JSW+37/2Wukf/+ADLtCY7Ntn0yFTU49cAeo4VnHWqhUXNAEAoCbeeEMaOdKqp8vPTgGABlSv4diAAQPUp08fvfjii2XLunXrposuukgTJ06stP7dd9+t9957T2vdK4dJGjNmjL755hstXbpUkjRixAjl5+frww8/LFvnnHPO0XHHHafp06dXOY6CggIVlLsSVn5+vtq1a0c4diQrV9o0Jzfsuuwya1rdtWv9/LyiIgu0li+XFi2yN8fqmj23aWPVa5GRvlM1Dx2yyo2iIv/H0KqVVXyNGWNTRbOzran+7Nk2porBX/Pm3pDt+uvtTR0AAABAzXz7rfXvjI62qmwAoeOOO6T/K2QKdf6EY9VcsquywsJCLVu2TH/+8599lmdkZGjJkiVVPmfp0qXKyMjwWXb22Wdr6tSpKioqUlRUlJYuXao77rij0jqTJk067FgmTpyoBx980J/hQ7IryD3/vFWPjRtX/29WUVF2ZbQePezskSRt22ah1IIFVq2VnW23gwel7dvtdjjNmkk9e3r7mZ10kv2MilfU27zZQsBbb7Xm2+UvQNCunTXpvv12+1n/+pdVkZSvOqM6BAAAAKidrl3tBPXOnXa1ZgCh48orAz2CgPArHNuxY4dKSkqUmJjoszwxMVG5ublVPic3N7fK9YuLi7Vjxw4lJycfdp3DvaYkTZgwQePHjy/72q0cQw3cfLPdAiUx0SrWLrvMu8xx7Ap32dk2pdNxfKdsNm1qwVjbtlX3/EpP9/26tLRmvcHatLHqMAAAAAB1IzrargLtXtQKQOg4+eRAjyAg/ArHXJ4KVTWO41RadqT1Ky739zVjYmIUU11/KoQWj8fOLrVqZdVtR4um+QAAAEDgdOpkNwAIAX4lCAkJCYqMjKxU0bV9+/ZKlV+upKSkKtdv0qSJWrVqVe06h3tNAAAAAAAAoC74FY5FR0crLS1NmZmZPsszMzM1aNCgKp+Tnp5eaf358+erb9++ioqKqnadw70mAAAAAAAAUBf8nlY5fvx4jRw5Un379lV6erpefvllZWVlacyYMZKsF9iWLVv0+uuvS7IrUz7//PMaP368Ro8eraVLl2rq1Kk+V6EcO3ashg4dqscee0wXXnih5s6dq48//liLFy+uo18TAAAAAAAAqMzvcGzEiBHauXOnHnroIeXk5Khnz56aN2+eOnToIEnKyclRVlZW2fqdOnXSvHnzdMcdd+iFF15QSkqKnn32WV1a7tKggwYN0owZM3TvvffqvvvuU+fOnTVz5kwNGDCgxuNy+5jl5+f7+ysBAAAAAACgEXHzITcvqo7HqclaIeDnn3/mapUAAAAAAAAok52drbZt21a7TqMJx0pLS7V161Y1b9682qtchpL8/Hy1a9dO2dnZiouLC/RwEALYZuAvthn4i20GtcF2A3+xzcBfbDOoDbabxs1xHO3du1cpKSmKiKi+5b7f0yqDVURExBGTwFAVFxfHHyr8wjYDf7HNwF9sM6gNthv4i20G/mKbQW2w3TRe8fHxNVrPr6tVAgAAAAAAAI0J4RgAAAAAAADCFuFYEIuJidH999+vmJiYQA8FIYJtBv5im4G/2GZQG2w38BfbDPzFNoPaYLuBq9E05AcAAAAAAAD8ReUYAAAAAAAAwhbhGAAAAAAAAMIW4RgAAAAAAADCFuEYAAAAAAAAwhbhGAAAAAAAAMIW4ViQmjx5sjp16qTY2FilpaVp0aJFgR4SgsTEiRPVr18/NW/eXG3atNFFF12kdevW+axz3XXXyePx+NwGDhwYoBEj0B544IFK20NSUlLZ9x3H0QMPPKCUlBQ1bdpUp512mlavXh3AESMYdOzYsdJ24/F4dOutt0piPwNp4cKFOv/885WSkiKPx6N3333X5/s12bcUFBToD3/4gxISEnTsscfqggsu0M8//9yAvwUaUnXbTFFRke6++2716tVLxx57rFJSUnTNNddo69atPq9x2mmnVdr3XHnllQ38m6AhHWlfU5P3I/Y14eVI20xVxzcej0ePP/542Trsa8IP4VgQmjlzpsaNG6d77rlHK1as0JAhQzRs2DBlZWUFemgIAgsWLNCtt96qzz//XJmZmSouLlZGRob279/vs94555yjnJycstu8efMCNGIEgx49evhsD6tWrSr73j/+8Q899dRTev755/XVV18pKSlJZ511lvbu3RvAESPQvvrqK59tJjMzU5J0+eWXl63Dfia87d+/XyeffLKef/75Kr9fk33LuHHjNGfOHM2YMUOLFy/Wvn37NHz4cJWUlDTUr4EGVN02c+DAAS1fvlz33Xefli9frtmzZ+uHH37QBRdcUGnd0aNH++x7pkyZ0hDDR4AcaV8jHfn9iH1NeDnSNlN+W8nJydErr7wij8ejSy+91Gc99jVhxkHQ6d+/vzNmzBifZV27dnX+/Oc/B2hECGbbt293JDkLFiwoW3bttdc6F154YeAGhaBy//33OyeffHKV3ystLXWSkpKcv//972XLDh065MTHxzsvvfRSA40QoWDs2LFO586dndLSUsdx2M/AlyRnzpw5ZV/XZN+yZ88eJyoqypkxY0bZOlu2bHEiIiKcf//73w02dgRGxW2mKl9++aUjydm8eXPZslNPPdUZO3Zs/Q4OQauq7eZI70fsa8JbTfY1F154oXP66af7LGNfE36oHAsyhYWFWrZsmTIyMnyWZ2RkaMmSJQEaFYJZXl6eJKlly5Y+yz/77DO1adNGJ554okaPHq3t27cHYngIEuvXr1dKSoo6deqkK6+8Uhs3bpQkbdq0Sbm5uT77nJiYGJ166qnsc1CmsLBQb7zxhq6//np5PJ6y5exncDg12bcsW7ZMRUVFPuukpKSoZ8+e7H8gyY5xPB6PWrRo4bP8zTffVEJCgnr06KE777yTSmdU+37EvgbV2bZtmz744AONGjWq0vfY14SXJoEeAHzt2LFDJSUlSkxM9FmemJio3NzcAI0KwcpxHI0fP16nnHKKevbsWbZ82LBhuvzyy9WhQwdt2rRJ9913n04//XQtW7ZMMTExARwxAmHAgAF6/fXXdeKJJ2rbtm165JFHNGjQIK1evbpsv1LVPmfz5s2BGC6C0Lvvvqs9e/bouuuuK1vGfgbVqcm+JTc3V9HR0TruuOMqrcMxDw4dOqQ///nPuuqqqxQXF1e2/Oqrr1anTp2UlJSk7777ThMmTNA333xTNvUb4edI70fsa1Cd1157Tc2bN9cll1zis5x9TfghHAtS5c/MSxaCVFwG3Hbbbfr222+1ePFin+UjRowoe9yzZ0/17dtXHTp00AcffFBpx4/Gb9iwYWWPe/XqpfT0dHXu3FmvvfZaWcNa9jmoztSpUzVs2DClpKSULWM/g5qozb6F/Q+Kiop05ZVXqrS0VJMnT/b53ujRo8se9+zZU6mpqerbt6+WL1+uPn36NPRQEQRq+37EvgaS9Morr+jqq69WbGysz3L2NeGHaZVBJiEhQZGRkZXOYmzfvr3S2VeEtz/84Q9677339Omnn6pt27bVrpucnKwOHTpo/fr1DTQ6BLNjjz1WvXr10vr168uuWsk+B4ezefNmffzxx7rhhhuqXY/9DMqryb4lKSlJhYWF2r1792HXQfgpKirSFVdcoU2bNikzM9Onaqwqffr0UVRUFPselKn4fsS+BoezaNEirVu37ojHOBL7mnBAOBZkoqOjlZaWVqlcMzMzU4MGDQrQqBBMHMfRbbfdptmzZ+uTTz5Rp06djvicnTt3Kjs7W8nJyQ0wQgS7goICrV27VsnJyWXl4uX3OYWFhVqwYAH7HEiSXn31VbVp00bnnXdeteuxn0F5Ndm3pKWlKSoqymednJwcfffdd+x/wpQbjK1fv14ff/yxWrVqdcTnrF69WkVFRex7UKbi+xH7GhzO1KlTlZaWppNPPvmI67KvafyYVhmExo8fr5EjR6pv375KT0/Xyy+/rKysLI0ZMybQQ0MQuPXWW/XWW29p7ty5at68edlZ+fj4eDVt2lT79u3TAw88oEsvvVTJycn66aef9Je//EUJCQm6+OKLAzx6BMKdd96p888/X+3bt9f27dv1yCOPKD8/X9dee608Ho/GjRunRx99VKmpqUpNTdWjjz6qY445RldddVWgh44AKy0t1auvvqprr71WTZp4DxnYz0Cy7WDDhg1lX2/atEkrV65Uy5Yt1b59+yPuW+Lj4zVq1Cj98Y9/VKtWrdSyZUvdeeed6tWrl84888xA/VqoR9VtMykpKbrsssu0fPly/etf/1JJSUnZMU7Lli0VHR2tH3/8UW+++abOPfdcJSQkaM2aNfrjH/+o3r17a/DgwYH6tVDPqttuWrZsecT3I/Y14edI70+SlJ+fr7fffltPPvlkpeezrwlTAbxSJqrxwgsvOB06dHCio6OdPn36OAsWLAj0kBAkJFV5e/XVVx3HcZwDBw44GRkZTuvWrZ2oqCinffv2zrXXXutkZWUFduAImBEjRjjJyclOVFSUk5KS4lxyySXO6tWry75fWlrq3H///U5SUpITExPjDB061Fm1alUAR4xg8dFHHzmSnHXr1vksZz8Dx3GcTz/9tMr3o2uvvdZxnJrtWw4ePOjcdtttTsuWLZ2mTZs6w4cPZztqxKrbZjZt2nTYY5xPP/3UcRzHycrKcoYOHeq0bNnSiY6Odjp37uzcfvvtzs6dOwP7i6FeVbfd1PT9iH1NeDnS+5PjOM6UKVOcpk2bOnv27Kn0fPY14cnjOI5T7wkcAAAAAAAAEIToOQYAAAAAAICwRTgGAAAAAACAsEU4BgAAAAAAgLBFOAYAAAAAAICwRTgGAAAAAACAsEU4BgAAAAAAgLBFOAYAAAAAAICwRTgGAAAAAACAsEU4BgAAAAAAgLBFOAYAAAAAAICwRTgGAAAAAACAsPX/AZFj2Jm5bipiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "plot_array(X_train[idx], y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class zero samples: 3237, Class one samples: 8403\n",
      "Based on this information, we can see that the dataset is imbalanced. We use balanced accuracy as metric.\n"
     ]
    }
   ],
   "source": [
    "cls_0 = np.count_nonzero(y_train == 0)\n",
    "cls_1 = np.count_nonzero(y_train == 1)\n",
    "print(f'Class zero samples: {cls_0}, Class one samples: {cls_1}')\n",
    "print('Based on this information, we can see that the dataset is imbalanced. We use balanced accuracy as metric.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM balanced accuracy: 0.8813936043937409\n",
      "Random Forest balanced accuracy: 0.9519740746672194\n"
     ]
    }
   ],
   "source": [
    "svm_clf_no_features = svm.SVC()\n",
    "svm_clf_no_features.fit(X_train, y_train)\n",
    "\n",
    "svm_preds = svm_clf_no_features.predict(X_test)\n",
    "svm_acc_no_features = balanced_accuracy_score(y_test, svm_preds)\n",
    "print(f'SVM balanced accuracy: {svm_acc_no_features}')\n",
    "\n",
    "rf_clf_no_features = RandomForestClassifier()\n",
    "rf_clf_no_features.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_clf_no_features.predict(X_test)\n",
    "rf_acc_no_features = balanced_accuracy_score(y_test, rf_preds)\n",
    "print(f'Random Forest balanced accuracy: {rf_acc_no_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11640, 188)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['id'] = range(len(df_train))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_feautures = extract_features(df_train, column_id='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    # Define the loss function and the optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move the model to the device\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # Loop over the epochs\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in dataloader:\n",
    "            # Move inputs and targets to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} Loss: {loss.item()}')\n",
    "        \n",
    "def create_dataloader(X, y, batch_size=32):\n",
    "    # Convert X and y to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    # Wrap them in a TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "    # Create a DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for inputs, _ in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.detach().numpy())\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel_uni(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel_uni, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_uni = RNNModel_uni(input_size=188, hidden_size=20, output_size=1)\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train)\n",
    "test_loader = create_dataloader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.562950611114502\n",
      "Epoch 2/10 Loss: 0.5527372360229492\n",
      "Epoch 3/10 Loss: 0.5271729230880737\n",
      "Epoch 4/10 Loss: 0.5013760328292847\n",
      "Epoch 5/10 Loss: 0.47758159041404724\n",
      "Epoch 6/10 Loss: 0.45576012134552\n",
      "Epoch 7/10 Loss: 0.43663549423217773\n",
      "Epoch 8/10 Loss: 0.42029136419296265\n",
      "Epoch 9/10 Loss: 0.4061427116394043\n",
      "Epoch 10/10 Loss: 0.39348745346069336\n"
     ]
    }
   ],
   "source": [
    "train_model(rnn_uni, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN unidirectional balanced accuracy: 0.8343527145293026\n"
     ]
    }
   ],
   "source": [
    "preds_rnn = get_predictions(rnn_uni.to('cpu'), test_loader)\n",
    "rnn_uni_acc = balanced_accuracy_score(y_test, preds_rnn)\n",
    "print(f'RNN unidirectional balanced accuracy: {rnn_uni_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel_bi(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel_bi, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_bi = RNNModel_bi(input_size=188, hidden_size=20, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.5810989737510681\n",
      "Epoch 2/10 Loss: 0.5747668147087097\n",
      "Epoch 3/10 Loss: 0.5498577952384949\n",
      "Epoch 4/10 Loss: 0.5226210355758667\n",
      "Epoch 5/10 Loss: 0.49521392583847046\n",
      "Epoch 6/10 Loss: 0.468561589717865\n",
      "Epoch 7/10 Loss: 0.44439369440078735\n",
      "Epoch 8/10 Loss: 0.42383307218551636\n",
      "Epoch 9/10 Loss: 0.4065588414669037\n",
      "Epoch 10/10 Loss: 0.3916075825691223\n"
     ]
    }
   ],
   "source": [
    "train_model(rnn_bi, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN bidirectional balanced accuracy: 0.8385430895610969\n"
     ]
    }
   ],
   "source": [
    "preds_rnn_bi = get_predictions(rnn_bi.to('cpu'), test_loader)\n",
    "rnn_bi_acc = balanced_accuracy_score(y_test, preds_rnn_bi)\n",
    "print(f'RNN bidirectional balanced accuracy: {rnn_bi_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_vanilla(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_vanilla, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64*21, 128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.relu3(self.conv3(x))      \n",
    "        x = self.maxpool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_vanilla = CNN_vanilla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.477226585149765\n",
      "Epoch 2/10 Loss: 0.3644581437110901\n",
      "Epoch 3/10 Loss: 0.3170540928840637\n",
      "Epoch 4/10 Loss: 0.2698150873184204\n",
      "Epoch 5/10 Loss: 0.19000652432441711\n",
      "Epoch 6/10 Loss: 0.13961845636367798\n",
      "Epoch 7/10 Loss: 0.11545458436012268\n",
      "Epoch 8/10 Loss: 0.08325661718845367\n",
      "Epoch 9/10 Loss: 0.0797644853591919\n",
      "Epoch 10/10 Loss: 0.06020338460803032\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_vanilla, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla CNN balanced accuracy: 0.9622683724128835\n"
     ]
    }
   ],
   "source": [
    "preds_cnn_van = get_predictions(conv_vanilla.to('cpu'), test_loader)\n",
    "cnn_van_preds = balanced_accuracy_score(y_test, preds_cnn_van)\n",
    "print(f'Vanilla CNN balanced accuracy: {cnn_van_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.linear = nn.Linear(12032, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.unsqueeze(1)\n",
    "        out = self.relu(self.bn1(self.conv1(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Define the model\n",
    "model = ResNet(ResidualBlock, [2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvResNet = ResNet(ResidualBlock, [2, 2], num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.4102168083190918\n",
      "Epoch 2/10 Loss: 0.16520681977272034\n",
      "Epoch 3/10 Loss: 0.054639529436826706\n",
      "Epoch 4/10 Loss: 0.025744736194610596\n",
      "Epoch 5/10 Loss: 0.055238232016563416\n",
      "Epoch 6/10 Loss: 0.0013530653668567538\n",
      "Epoch 7/10 Loss: 0.0856984481215477\n",
      "Epoch 8/10 Loss: 0.0010074415476992726\n",
      "Epoch 9/10 Loss: 0.0008420449448749423\n",
      "Epoch 10/10 Loss: 0.002857866231352091\n"
     ]
    }
   ],
   "source": [
    "train_model(ConvResNet, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla CNN balanced accuracy: 0.8908023711505308\n"
     ]
    }
   ],
   "source": [
    "preds_cnn_res = get_predictions(conv_vanilla.to('cpu'), test_loader)\n",
    "cnn_res_preds = balanced_accuracy_score(y_test, preds_cnn_res)\n",
    "print(f'Vanilla CNN balanced accuracy: {cnn_res_preds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer based classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSTConfig, PatchTSTForClassification\n",
    "\n",
    "config = PatchTSTConfig(\n",
    "    num_input_channels=1,\n",
    "    num_targets=1,\n",
    "    context_length=188,\n",
    "    patch_length=12,\n",
    "    stride=12,\n",
    "    use_cls_token=True,\n",
    ")\n",
    "\n",
    "transformer = PatchTSTForClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input sequence length (32) doesn't match model configuration (188).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\patchtst\\modeling_patchtst.py:1516\u001b[0m, in \u001b[0;36mPatchTSTForClassification.forward\u001b[1;34m(self, past_values, target_values, past_observed_mask, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;124;03m    past_values (`torch.Tensor` of shape `(bs, sequence_length, num_input_channels)`, *required*):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;124;03m>>> labels = outputs.prediction_logits\u001b[39;00m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1516\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1523\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(model_output\u001b[38;5;241m.\u001b[39mlast_hidden_state)\n\u001b[0;32m   1525\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\patchtst\\modeling_patchtst.py:1235\u001b[0m, in \u001b[0;36mPatchTSTModel.forward\u001b[1;34m(self, past_values, past_observed_mask, future_values, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m   1232\u001b[0m scaled_past_values, loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler(past_values, past_observed_mask)\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;66;03m# patched_values: [bs x num_input_channels x num_patches x patch_length] for pretrain\u001b[39;00m\n\u001b[1;32m-> 1235\u001b[0m patched_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatchifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_past_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_mask_input:\n\u001b[0;32m   1237\u001b[0m     masked_values, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking(patched_values)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\patchtst\\modeling_patchtst.py:383\u001b[0m, in \u001b[0;36mPatchTSTPatchify.forward\u001b[1;34m(self, past_values)\u001b[0m\n\u001b[0;32m    381\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m past_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sequence_length \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length:\n\u001b[1;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput sequence length (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match model configuration (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# output: [bs x new_sequence_length x num_channels]\u001b[39;00m\n\u001b[0;32m    387\u001b[0m output \u001b[38;5;241m=\u001b[39m past_values[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_start :, :]\n",
      "\u001b[1;31mValueError\u001b[0m: Input sequence length (32) doesn't match model configuration (188)."
     ]
    }
   ],
   "source": [
    "train_model(transformer, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
