{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from tsfresh import extract_features, select_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_array(array, color='blue'):\n",
    "    if not color == 'blue':\n",
    "        if color == 1:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.plot(array, color=color)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/ptbdb_train.csv')\n",
    "df_test = pd.read_csv('data/ptbdb_test.csv')\n",
    "X = df_train.iloc[:, :-1].values\n",
    "y = df_train.iloc[:, -1].values\n",
    "X_test = df_test.iloc[:, :-1].values\n",
    "y_test = df_test.iloc[:, -1].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "plot_array(X[idx], y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class zero samples: 3237, Class one samples: 8403\n",
      "Based on this information, we can see that the dataset is imbalanced. We use balanced accuracy as metric.\n"
     ]
    }
   ],
   "source": [
    "cls_0 = np.count_nonzero(y == 0)\n",
    "cls_1 = np.count_nonzero(y == 1)\n",
    "print(f'Class zero samples: {cls_0}, Class one samples: {cls_1}')\n",
    "print('Based on this information, we can see that the dataset is imbalanced. We use balanced accuracy as metric.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM balanced accuracy: 0.8631821368142264\n",
      "Random Forest balanced accuracy: 0.9562316853521913\n"
     ]
    }
   ],
   "source": [
    "svm_clf_no_features = svm.SVC()\n",
    "svm_clf_no_features.fit(X_train, y_train)\n",
    "\n",
    "svm_preds = svm_clf_no_features.predict(X_val)\n",
    "svm_acc_no_features = balanced_accuracy_score(y_val, svm_preds)\n",
    "print(f'SVM balanced accuracy: {svm_acc_no_features}')\n",
    "\n",
    "rf_clf_no_features = RandomForestClassifier()\n",
    "rf_clf_no_features.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_clf_no_features.predict(X_val)\n",
    "rf_acc_no_features = balanced_accuracy_score(y_val, rf_preds)\n",
    "print(f'Random Forest balanced accuracy: {rf_acc_no_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11640, 187)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['id'] = range(len(df_train))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_feautures = extract_features(df_train, column_id='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    # Define the loss function and the optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move the model to the device\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # Loop over the epochs\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in dataloader:\n",
    "            # Move inputs and targets to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} Loss: {loss.item()}')\n",
    "        \n",
    "def create_dataloader(X, y, batch_size=32):\n",
    "    # Convert X and y to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    # Wrap them in a TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "    # Create a DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for inputs, _ in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.detach().numpy())\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel_uni(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel_uni, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_uni = RNNModel_uni(input_size=187, hidden_size=20, output_size=1)\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train)\n",
    "val_loader = create_dataloader(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.43225884437561035\n",
      "Epoch 2/10 Loss: 0.4043598771095276\n",
      "Epoch 3/10 Loss: 0.3792317807674408\n",
      "Epoch 4/10 Loss: 0.36261487007141113\n",
      "Epoch 5/10 Loss: 0.3504018783569336\n",
      "Epoch 6/10 Loss: 0.3398241698741913\n",
      "Epoch 7/10 Loss: 0.33003461360931396\n",
      "Epoch 8/10 Loss: 0.32098349928855896\n",
      "Epoch 9/10 Loss: 0.31262168288230896\n",
      "Epoch 10/10 Loss: 0.3048172891139984\n"
     ]
    }
   ],
   "source": [
    "train_model(rnn_uni, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN unidirectional balanced accuracy: 0.8054867343533924\n"
     ]
    }
   ],
   "source": [
    "preds_rnn = get_predictions(rnn_uni.to('cpu'), val_loader)\n",
    "rnn_uni_acc = balanced_accuracy_score(y_val, preds_rnn)\n",
    "print(f'RNN unidirectional balanced accuracy: {rnn_uni_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel_bi(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel_bi, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_bi = RNNModel_bi(input_size=187, hidden_size=20, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.4539634585380554\n",
      "Epoch 2/10 Loss: 0.41882553696632385\n",
      "Epoch 3/10 Loss: 0.39597031474113464\n",
      "Epoch 4/10 Loss: 0.3808786869049072\n",
      "Epoch 5/10 Loss: 0.36904001235961914\n",
      "Epoch 6/10 Loss: 0.3594372868537903\n",
      "Epoch 7/10 Loss: 0.3516429364681244\n",
      "Epoch 8/10 Loss: 0.3451738953590393\n",
      "Epoch 9/10 Loss: 0.3391295373439789\n",
      "Epoch 10/10 Loss: 0.3326413929462433\n"
     ]
    }
   ],
   "source": [
    "train_model(rnn_bi, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN bidirectional balanced accuracy: 0.8210617426952798\n"
     ]
    }
   ],
   "source": [
    "preds_rnn_bi = get_predictions(rnn_bi.to('cpu'), val_loader)\n",
    "rnn_bi_acc = balanced_accuracy_score(y_val, preds_rnn_bi)\n",
    "print(f'RNN bidirectional balanced accuracy: {rnn_bi_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_vanilla(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_vanilla, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64*21, 1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.relu3(self.conv3(x))      \n",
    "        x = self.maxpool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_vanilla = CNN_vanilla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.3430253565311432\n",
      "Epoch 2/10 Loss: 0.3656424283981323\n",
      "Epoch 3/10 Loss: 0.36547330021858215\n",
      "Epoch 4/10 Loss: 0.35912027955055237\n",
      "Epoch 5/10 Loss: 0.3607717752456665\n",
      "Epoch 6/10 Loss: 0.34869539737701416\n",
      "Epoch 7/10 Loss: 0.3442457914352417\n",
      "Epoch 8/10 Loss: 0.3506646454334259\n",
      "Epoch 9/10 Loss: 0.3340754806995392\n",
      "Epoch 10/10 Loss: 0.32475459575653076\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_vanilla, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla CNN balanced accuracy: 0.8322439631556792\n"
     ]
    }
   ],
   "source": [
    "preds_cnn_van = get_predictions(conv_vanilla.to('cpu'), val_loader)\n",
    "cnn_van_preds = balanced_accuracy_score(y_val, preds_cnn_van)\n",
    "print(f'Vanilla CNN balanced accuracy: {cnn_van_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.linear = nn.Linear(12032, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.unsqueeze(1)\n",
    "        out = self.relu(self.bn1(self.conv1(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Define the model\n",
    "model = ResNet(ResidualBlock, [2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvResNet = ResNet(ResidualBlock, [2, 2], num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.3068926930427551\n",
      "Epoch 2/10 Loss: 0.03513769432902336\n",
      "Epoch 3/10 Loss: 0.013993089087307453\n",
      "Epoch 4/10 Loss: 0.0033749411813914776\n",
      "Epoch 5/10 Loss: 0.014176075346767902\n",
      "Epoch 6/10 Loss: 0.007326065097004175\n",
      "Epoch 7/10 Loss: 0.028085099533200264\n",
      "Epoch 8/10 Loss: 0.004148954059928656\n",
      "Epoch 9/10 Loss: 0.041037727147340775\n",
      "Epoch 10/10 Loss: 0.0002616677666082978\n"
     ]
    }
   ],
   "source": [
    "train_model(ConvResNet, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla CNN balanced accuracy: 0.8322439631556792\n"
     ]
    }
   ],
   "source": [
    "preds_cnn_res = get_predictions(conv_vanilla.to('cpu'), val_loader)\n",
    "cnn_res_preds = balanced_accuracy_score(y_val, preds_cnn_res)\n",
    "print(f'Vanilla CNN balanced accuracy: {cnn_res_preds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer based classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.embedding.positional_encoding import PostionalEncoding\n",
    "from models.model.encoder import Encoder\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, d_model, seq_len, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(d_model*seq_len, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.seq(x)\n",
    "        return x\n",
    "    \n",
    "class Transformer_(nn.Module):\n",
    "    def __init__(self, d_model=100, n_head=4, max_len=5000, seq_len=200, ffn_hidden=128, n_layers=2, drop_prob=0.1):\n",
    "        super(Transformer_, self).__init__()\n",
    "        self.encoder_input_layer = nn.Linear(1,d_model)\n",
    "        \n",
    "        self.pos_emb = PostionalEncoding(max_seq_len=max_len,batch_first=False, d_model=d_model,dropout=0.1)\n",
    "        self.encoder = Encoder(d_model=d_model, n_head=n_head, ffn_hidden=ffn_hidden, drop_prob=drop_prob, n_layers=n_layers, details=False, device='cuda')\n",
    "        self.classHead = ClassificationHead(d_model=d_model, seq_len=seq_len, num_classes=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_input_layer(x)\n",
    "        x = self.pos_emb(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.classHead(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len=187 # sequence length of time series\n",
    "max_len=5000 # max time series sequence length \n",
    "n_head = 2 # number of attention head\n",
    "n_layer = 1# number of encoder layer\n",
    "drop_prob = 0.1\n",
    "d_model = 200 # number of dimension ( for positional embedding)\n",
    "ffn_hidden = 128 # size of hidden layer before classification \n",
    "feature = 1 # for univariate time series (1d), it must be adjusted for 1. \n",
    "batch_size = 100\n",
    "transformer = Transformer_(  d_model=d_model, n_head=n_head, max_len=max_len, seq_len=sequence_len, ffn_hidden=ffn_hidden, n_layers=n_layer, drop_prob=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x187 and 1x200)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[121], line 30\u001b[0m, in \u001b[0;36mTransformer_.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_input_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(x)\n\u001b[0;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x187 and 1x200)"
     ]
    }
   ],
   "source": [
    "train_model(transformer, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
